[["index.html", "Artifex - Fall 2022 Course Overview - Artifex Fall 2022 Prerequisites and Preparations References", " Artifex - Fall 2022 David Reynolds 2022-11-29 Course Overview - Artifex Fall 2022 Welcome to Artifex! The primary objective of this course/ club is to equip its members with the essential skills of a data scientist by working through a real world business analytics project with an industry partner. The course delivery is a mix of lectures and project-based learning. The lectures will all be tailored to our project and will be more prevalent in the beginning of the course. All lecture materials will be posted on this website. Further details on the partner project will be posted on Canvas. Prerequisites and Preparations You should have some basic knowledge of R, and be familiar with the topics covered in the Chapters 1 and 2 here. Have a recent version of R and RStudio installed. Install and load the tidyverse package. References Grolemund, G &amp; Wickham, H (2017): R for Data Science http://r4ds.had.co.nz Hyndman, R &amp; Athanasopoulos, G (2022): Forecasting: Principles and Practice https://otexts.com/fpp2/index.html "],["data-processing.html", "Chapter 1 Data Processing 1.1 Cleaning up strings 1.2 Assignment 1", " Chapter 1 Data Processing To motivate this section on data processing, we will use the (fictional) data below that contains order information for a retail company. As is almost always the case, this data needs some pre-processing before it is in shape for exploration and analysis. Copy and paste the code below to obtain this data frame in your environment. The processing steps we carry out below rely on the lubridate package, so start your script with library(lubridate). set.seed(1) customer = c(&quot;113 - Shaws&quot;, &quot;217 - Shaws&quot;, &quot;2114 - WalMart&quot;, &quot;99 - WalMart&quot;, &quot;23 - CVS&quot;, &quot;09 - CVS&quot;) # numbers dash name product = c(&quot;WX1X - 9 gal - Jelly&quot;, &quot;WX1P - 4 gal - Jelly&quot;, &quot;QP1X - 11 gal - Grape Juice&quot;, &quot;QP1 - 7 gal - Fruit Juice&quot;, &quot;TYL - 1 gal - Peanut Butter&quot;, &quot;LL - 2 gal - Jam&quot;) # letters size description business_unit = c(&quot;123 Retail&quot;, &quot;437 Consumer&quot;, &quot;990 International&quot;, &quot;222 Retail&quot;, &quot;49 Consumer&quot;, &quot;09 International&quot;) # number dash name df = data.frame(customer, product, business_unit, &quot;1-1-2022&quot; = rpois(6, 1100), &quot;2-1-2022&quot; = rpois(6, 1200), check.names = F) Table 1.1: A fake dataset on product shipments. customer product business_unit 1-1-2022 2-1-2022 113 - Shaws WX1X - 9 gal - Jelly 123 Retail 1079 1225 217 - Shaws WX1P - 4 gal - Jelly 437 Consumer 1144 1219 2114 - WalMart QP1X - 11 gal - Grape Juice 990 International 1142 1189 99 - WalMart QP1 - 7 gal - Fruit Juice 222 Retail 1113 1172 23 - CVS TYL - 1 gal - Peanut Butter 49 Consumer 1048 1178 09 - CVS LL - 2 gal - Jam 09 International 1116 1189 Our pre-processing of this particular dataset consists primarily of cleaning up the character (string) variables and dealing with dates. 1.1 Cleaning up strings For a reference on the use of strings in R, see this excellent resource. For the purpose of our analysis, some aspects of this dataset that are distracting for analysis include: The meaningless (to us) numbers that precede the customer name and business unit. The meaningless letters that precede the product description. The product variable includes the size which would ideally exist in its own column (i.e., we want a size column whose first entry is 9) Let’s work through each of these using the functions str_sub, str_locate, and str_split. Let’s first go over what these functions do and how they can be used for this task. str_sub(&quot;The big short&quot;, start = 5, end = 7) # big # the input can also be a vector x &lt;- c(&quot;Apple&quot;, &quot;Banana&quot;, &quot;Pear&quot;) # character vector str_sub(x, 1, 3) # &quot;App&quot; &quot;Ban&quot; &quot;Pea&quot; str_locate(&quot;This&quot;, &quot;s&quot;) # gives the starting and ending position of the &#39;s&#39; in &#39;This&#39; How can these two functions (str_sub, str_locate) be used in conjunction to deal with the first issue identified above? Try this out using the first entry from customer. The patterns that are located can be much more general than a literal letter. These patters are known as regular expressions. For example, suppose we would like to locate the part of the string that consists of the letter a followed by any number. The regular expression that represents any digit is \\d. str_locate(&quot;aardvark a3&quot;, &quot;a\\\\d&quot;) # 10 11 For more on matching regular expressions in R, see this document on the topic. Next, let’s deal with the product variable. This variable contains two potentially useful pieces of information and one useless piece. They are separated by a dash. This presents a good use case for the str_split function. Here is an example where we have two data points that are separated by a colon and we would like to extract them. str_split(&quot;200:300&quot;, &quot;:&quot;, simplify = T) # 200 300 What should we split the product variable on? This will give us a matrix, with two useful columns. We want to grab these columns and include them in our data frame as size and product_name. Refresher on how to carry out these sorts of tasks - How R thinks about data. 1.2 Assignment 1 Use the functions described above (str_sub, str_locate, and str_split) to obtain the following cleaned up data frame. customer product business_unit 1-1-2022 2-1-2022 size Shaws Jelly Retail 1079 1225 9 gal Shaws Jelly Consumer 1144 1219 4 gal WalMart Grape Juice International 1142 1189 11 gal WalMart Fruit Juice Retail 1113 1172 7 gal CVS Peanut Butter Consumer 1048 1178 1 gal CVS Jam International 1116 1189 2 gal Dealing with dates (part 1). The output from part one gets us pretty close to our desired analytic dataset. However, it turns out that for our analysis we would like the data to be in long format, where each row contains information on a single month. So, the first row of the dataset would have the January 2022 units of 9 gal Jelly shipped to Shaw’s. This is achieved using the function pivot_longer. Let’s take a look at the example from the documentation to figure out what parameters to use to achieve this Once you figure out the appropriate arguments for pivot_longer, the head of your new data frame should look like this: customer product business_unit size month units Shaws Jelly Retail 9 gal 1-1-2022 1079 Shaws Jelly Retail 9 gal 2-1-2022 1225 Shaws Jelly Consumer 4 gal 1-1-2022 1144 Shaws Jelly Consumer 4 gal 2-1-2022 1219 WalMart Grape Juice International 11 gal 1-1-2022 1142 WalMart Grape Juice International 11 gal 2-1-2022 1189 Dealing with dates (part 2). Finally, we want R to recognize our month variable as a date (rather than a character). A helpful package for dates is lubridate. Download and load this package into your workspace and use the function mdy on the month variable to coerce this variable to become a date. The str of your data frame should now look like this: ## tibble [12 × 6] (S3: tbl_df/tbl/data.frame) ## $ customer : chr [1:12] &quot;Shaws&quot; &quot;Shaws&quot; &quot;Shaws&quot; &quot;Shaws&quot; ... ## $ product : chr [1:12] &quot;Jelly&quot; &quot;Jelly&quot; &quot;Jelly&quot; &quot;Jelly&quot; ... ## $ business_unit: chr [1:12] &quot;Retail&quot; &quot;Retail&quot; &quot;Consumer&quot; &quot;Consumer&quot; ... ## $ size : chr [1:12] &quot;9 gal&quot; &quot;9 gal&quot; &quot;4 gal&quot; &quot;4 gal&quot; ... ## $ month : Date[1:12], format: &quot;2022-01-01&quot; &quot;2022-02-01&quot; ... ## $ units : int [1:12] 1079 1225 1144 1219 1142 1189 1113 1172 1048 1178 ... Notice how the month variable has format Date. Your data frame is now ready for exploration and analysis! "],["data-manipulation.html", "Chapter 2 Data Manipulation 2.1 Filter 2.2 Arrange 2.3 Select 2.4 Mutate 2.5 Group-By/ Summarise 2.6 Assignment 2", " Chapter 2 Data Manipulation We will discuss data transformation using data for all flights that departed NYC (i.e. JFK, LGA or EWR) in 2013. This data is contained in the flights data frame that comes from the nycflights13 package. Before beginning, install this package and load it (using nycflights13). There are five key dplyr functions that allow you to solve the vast majority of your data manipulation challenges: Pick observations by their values (filter()). Reorder the rows (arrange()). Pick variables by their names (select()). Create new variables with functions of existing variables (mutate()). Collapse many values down to a single summary (summarise()). This is often used in conjunction with group_by(), which changes the scope of each function from operating on the entire dataset to operating on it group-by-group. Let’s go through a quick use case for each of these. Further detail can be found here. 2.1 Filter Suppose we want to look at just morning flights (before 10am). morning_df = filter(flights, hour &lt; 10) How about morning flights in January. morning_df = filter(flights, hour &lt; 10, month == 1) 2.2 Arrange What are the attributes of the flights with the biggest departure delays? arrange(flights, desc(dep_delay)) 2.3 Select Suppose we don’t care about the flight number. arrange(flights, !flight) 2.4 Mutate Suppose we want to add a speed variable. mutate(flights, speed = distance/air_time * 60) 2.5 Group-By/ Summarise Suppose we want to know the mean departure delay by airline. flights %&gt;% group_by(carrier) %&gt;% summarize(mean_delay = mean(dep_delay, na.rm = T), n = n()) %&gt;% arrange(desc(mean_delay)) 2.6 Assignment 2 How many flights … Had an arrival delay of two or more hours Flew to Houston (IAH or HOU) Were operated by United, American, or Delta Departed in summer (July, August, and September) Arrived more than two hours late, but didn’t leave late Were delayed by at least an hour, but made up over 30 minutes in flight Add two new variables to flights that convert dep_time and arr_time to a more convenient representation of number of minutes since midnight. Look at the number of canceled flights per day. Is there a pattern over the course of the year? How about the proportion of canceled flights over the course of the year? What time of day should you fly if you want to avoid delays as much as possible? "],["time-series.html", "Chapter 3 Time Series 3.1 Decomposition 3.2 Forecasting 3.3 Statistical model", " Chapter 3 Time Series 3.1 Decomposition We want to decompose our time series into three parts: a trend component (\\(T\\)), a seasonality component (\\(S\\)), and a random component (\\(R\\)). That is, for each observation \\(Y_t\\), we want to break it down into three parts: \\(Y_T = T_t + S_t + R_t\\) First, let’s talk about the trend component (T). The trend component is a moving average, which you can obtain using the ma function within the forecast library. set.seed(1) # generate some fake data that resembles our real dataset (noce the week_no variable, which # corresponds with the enterprise week number from your original data) trend = seq( from = 10, to = 10 + 52 * 3 - 1, by = 1) df = data.frame( invoiced = trend + (rnorm(52 * 3, mean = 25, sd = 40)), week_no = rep(1:52, 3), # week number id = 1:(52 * 3)) plot(df$invoiced, type = &quot;l&quot;) y_ts = ts(df$invoiced, frequency = 52) # make your data into a time series object df$trend = ma(y_ts, order = 52) # use the ma function from the forecast library Now that we have added a trend variable to our data frame, let’s get the seasonal (\\(S\\)) component. To estimate the seasonal component for each week, simply average the detrended values for that week. These seasonal component values are then adjusted to ensure that they add to zero. # 1. subtract the trend df$detrend = df$invoiced - df$trend # 2. group by week number and take the average of the de-trended values df = df %&gt;% group_by(week_no) %&gt;% mutate(S1 = mean(detrend, na.rm = T)) %&gt;% ungroup() %&gt;% mutate(S = S1 - mean(S1)) %&gt;% # make sure the sum of the seasonal components is 0 select(!c(detrend, S1)) Finally, the random component is calculated by subtracting the estimated seasonal and trend-cycle components. That is, \\(R_t = Y_t - T_t - S_t\\). df = mutate(df, R = invoiced - trend - S) Now, plot each line: df %&gt;% pivot_longer(!(c(&quot;week_no&quot;, &quot;id&quot;))) %&gt;% ggplot(aes(id, value, color = name)) + geom_line() + theme_minimal() + ggtitle(&quot;Decomposition of invoiced time series&quot;) 3.2 Forecasting Let’s consider some very simple potential forecast models. The simplest potential model is to forecast future values as the last observed value. That is, \\[\\begin{equation} \\hat{y}_{T+1 | T} = y_T \\end{equation}\\] Another very simple model consists of forecasting future values as the average over the entire observed series. That is, \\[\\begin{equation} \\hat{y}_{T+1 | T} = \\frac{1}{T} \\sum_{i=1}^T y_i \\end{equation}\\] A slightly more complicated approach that typically works better is to forecast future values as a weighted average of past values, with higher weights assigned to more recent observations. This model can be expressed as, \\[\\begin{equation} \\hat{y}_{T+h | T} = \\alpha y_T + (1-\\alpha) \\hat{y}_{T | T - 1} \\end{equation}\\] How can we show that weights are decreasing in time? What does this expression imply about forecasts from this model? This is implemented in ses below. The next level up in complexity is using the same idea but adding a trend estimate. In this case, the forecast values are, \\[\\begin{equation} \\hat{y}_{T+h | T} = l_T + h b_T, \\end{equation}\\] Where \\(l\\) is the estimated level of the time series and \\(b_T\\) is the estimated trend at time \\(T\\). What does this expression imply about forecasts from this model? This is implemented in holt below. fx1 &lt;- ses(y_ts, h=5) fx2 &lt;- holt(y_ts, h=15) round(accuracy(fx1),2) ## ME RMSE MAE MPE MAPE MASE ACF1 ## Training set 6.46 37.15 28.71 -21.53 55.35 0.56 -0.08 autoplot(y_ts) + autolayer(fx1, series=&quot;Simple Exponential Smoothing&quot;, PI=F) + autolayer(fx2, series=&quot;Holt Winters&quot;, PI=F) + ylab(&quot;Invoiced&quot;) + xlab(&quot;Year&quot;) 3.3 Statistical model One of the drawbacks of the forecasting methods we have used so far is that there is no uncertainty quantification. Fortunately, there is an easy way to formulate the exponential smoothing models we have been working with as a statistical model. For more detail, see this excellent resource. mod = ets(y_ts, model=&quot;ZZZ&quot;, damped=NULL, alpha=NULL, beta=NULL, gamma=NULL, phi=NULL, lambda=NULL, biasadj=FALSE, additive.only=FALSE, restrict=TRUE, allow.multiplicative.trend=FALSE) Once the model is fit, we can see which model was chosen using the summary function. We label each state space model as ETS( \\(\\cdot, \\cdot, \\cdot\\)), for (Error, Trend, Seasonal). The possibilities for each component are: Error = {\\(A,M\\)}, Trend = {\\(N,A,A_d\\)}, and Seasonal = {\\(N,A,M\\)}. Here, \\(M\\) denotes multiply and \\(A\\) denotes add. In an \\(M\\) type model, the component multiplies (i.e., a season in which invoices are 1.1 times as large). ## ETS(A,A,N) ## ## Call: ## ets(y = y_ts, model = &quot;ZZZ&quot;, damped = NULL, alpha = NULL, beta = NULL, ## ## Call: ## gamma = NULL, phi = NULL, additive.only = FALSE, lambda = NULL, ## ## Call: ## biasadj = FALSE, restrict = TRUE, allow.multiplicative.trend = FALSE) ## ## Smoothing parameters: ## alpha = 0.002 ## beta = 0.002 ## ## Initial states: ## l = 30.6217 ## b = 1.054 ## ## sigma: 35.968 ## ## AIC AICc BIC ## 1911.506 1911.906 1926.755 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE MASE ACF1 ## Training set -2.913354 35.50392 28.2599 -29.14288 55.95159 0.552141 -0.03601155 There is also a straightforward way to forecast using the fitted model. mod %&gt;% forecast(h=15) %&gt;% autoplot() To do Cut your time series into a training set (all but the last 3 months of data) and a test set (last 3 months) Fit a state-space model using ETS to your (weekly) time series. What model was chosen? Compare forecasts for 12 weeks ahead to the actual data. Now make your training set and test set into monthly data and repeat step 2. On a monthly basis, how do the residuals of the weekly model compare to the residuals of the monthly model? "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
